# 前端领域有哪些跨端方案？  
  
跨平台指的是跨操作系统，而跨端是指客户端。  
  
客户端的特点就是有界面、有逻辑，所以包含逻辑跨端和渲染跨端。主要的客户端有 web、安卓、ios、iot 设备等。  
  
现在主流的跨端方案有 react native、weex、flutter、kraken 以及各家自研的跨端引擎等。  
  
### react native  
  
跨端包括逻辑跨端和渲染跨端，rn 的逻辑跨端是基于 js 引擎，通过 bridge 注入一些设备能力的 api，而渲染跨端则是使用安卓、ios 实现 react 的 virtual dom 的渲染。  
  
![](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fe5fbab9c6314f0fa92a88eff863ddcd~tplv-k3u1fbpfcp-watermark.image)  
  
其中 native api 和组件（灰色画出的部分）并没有做到双端一致，而且有的时候扩展图中灰色部分需要原生配合，混杂 rn 代码和自己扩展的代码导致代码比较难管理。最著名的事件就是 airbnb 从最大的 react native 支持者到弃用 react native。  
  
### weex  
  
weex 也是类似的思路来实现跨端的，不过他对接的上层 ui 框架是 vue，而且努力做到了双端的组件 和 api 的一致性（虽然后续维护跟不上了）。架构和上图类似。  
  
### flutter  
  
flutter 是近些年流行的跨端方案，跨的端包括安卓、ios、web 等。它最大的特点是渲染不是基于操作系统的组件，而是直接基于绘图库（skia）来绘制的，这样做到了渲染的跨端。逻辑的跨端也不是基于 js 引擎，而是自研的 dart vm 来跨端，通过 dart 语言来写逻辑，  
  
![](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4ae085c6942147fb82518ae23f2975bb~tplv-k3u1fbpfcp-watermark.image)  
  
### kraken  
  
跨端包括两部分，渲染跨端和逻辑跨端。有时候只需要渲染跨端、有时候只需要逻辑跨端，有的时候需要完整的跨端引擎，这 3 种情况都有各自的适用场景。  
  
kraken 就是一个跨端渲染引擎，基于 flutter 的绘图能力实现了 css 的渲染，实现了渲染的跨端。  
  
![](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fe8504682ed44e939d3cbf6aaf1563a2~tplv-k3u1fbpfcp-watermark.image)  
  
### 自研渲染引擎  
  
跨端引擎很依赖底层实现的组件和 api，用开源方案也一样得扩展这部分，所以有一定规模的团队都会选择自研。  
  
自研跨端引擎会和 rn、weex 不同：  
  
- 渲染部分不需要实现 virtual dom 的渲染，而是直接对接 dom api，上层应用基于这些 dom api 实现跨端渲染。这样理论上可以对接任意前端框架。  
  
- 逻辑部分也是基于 js 引擎，通过 binding 直接注入一些 c++ 实现的 api，或者运行时通过 bridge 来注入一些安卓、ios 实现的 api。  
  
![](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/491a93e8f8734a22a05afe8c84731e08~tplv-k3u1fbpfcp-watermark.image)  
  
自研跨端引擎的好处是组件和 api 可以自己扩展，更快的响应业务的需求。其中组件和 api 的双端一致性，以及统一的 api 的设计都是难点。  
  
## 跨端的通用原理是什么  
  
其实跨端和跨平台的思路类似，都是实现一个容器，给它提供统一的 api，这套 api 由不同的平台各自实现，保证一致的功能。  
  
具体一些的话，跨端分为渲染和逻辑跨端，有的时候只需要单独的渲染跨端方案（比如 karen）和逻辑跨端方案，有的时候需要完整的跨端引擎。  
  
weex、react native 的渲染部分都是通过实现了 virtual dom 的渲染，用安卓、ios 各自的渲染方式实现，逻辑部分使用 js 引擎，通过 bridge 注入一些安卓、ios 的 api。  
  
flutter 则是直接使用 skia 绘图库绘制，并且逻辑跨端使用 dart vm。  
  
但是不管具体实现怎样，思路都大同小异：**跨端引擎需要实现一个渲染引擎、实现一个 vm，基于这套架构实现各种组件和 api，跨端容器上层对接一个 ui 框架，再上层的业务代码可以基于容器的 api 实现跨端的渲染和逻辑**  
  
## web container  
  
这两天 web container 比较火，其实也是一种跨平台技术，它是在浏览器里面实现的容器，通过 wasm 实现了 node 的 api，这样在这个容器里面可以跑 node 代码。其实思路比较常见，但是是一个新场景。  
  
  
![](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d3d86bfa23944052b610e5dbb88b7e04~tplv-k3u1fbpfcp-watermark.image)  
  
浏览器容器之上又跑了个容器，容器套娃。  
# 说说你对跨平台的理解  
我们知道，cpu 有不同的架构和指令集，上层也有不同的操作系统，一个系统的可执行文件在另一个系统上就是不可执行的，比如 windows 的 exe 文件在 mac 上就不能直接执行。不同的系统就是不同的运行平台。可执行文件是不跨平台的。  
  
不同平台提供的 api 不同，所以代码逻辑可能也不同，需要不同平台单独维护代码。这样就带来了几个问题：  
  
- 多平台各自开发，怎么保证功能是一致的  
- 多平台各自开发，那是不是得各自测试，开发和测试的人力都是多份的  
  
所以出现了跨平台的一些技术，目标是一份代码跑在任意平台。  
  
我们先来看一些各领域的跨平台方案：  
  
### 浏览器  
  
操作系统不同，浏览器上跑的网页的代码确实同一份。浏览器就是一种历史悠久的跨平台方案。  
  
网页跨平台不意味着浏览器也是跨平台的，浏览器的可执行文件还是每个平台单独开发和编译的，但是他们支持的网页解析逻辑一样，这样上面跑的网页就是跨平台的。  
  
浏览器提供了一个容器，屏蔽了底层差异，提供了统一的 api（dom api），这样就可以实现同一份代码跑在不同平台的统一的容器里。这个容器叫做浏览器引擎，由 js 引擎、渲染引擎等构成。  
  
![](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5acc7e2e83a74e33a82dae182209d836~tplv-k3u1fbpfcp-watermark.image)  
  
### docker   
  
docker 是一种虚拟化技术，可以在操作系统之上加一个虚拟层，在这层之上划分一到多个容器，容器里再去跑系统、app，这样可以实现硬件和软件的分离，动态分配硬件资源给容器，并且方便 app 运行环境的整体迁移（保存成镜像）。  
  
![](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ede8f79791d54e46977d77cfb6639081~tplv-k3u1fbpfcp-watermark.image)  
  
docker 很明显也是一种跨平台技术，同一个镜像可以跑在任何操作系统的 docker 上。只要不同操作系统实现同样的容器即可。  
  
### jvm  
  
java 是一门编译 + 解释的语言，java 源码编译成字节码，然后字节码直接在 vm 上解释执行。  
  
java 为什么这么火呢？主要是因为跨平台。  
  
c、c++ 这种语言写的代码需要编译成不同操作系统上的可执行文件来跑，而且每个平台的代码可能还不一样，需要写多份。  
  
java 因为提供了 jvm 容器，只要把源码编译成 jvm 能解释的字节码就行了，而且 jdk 提供了统一的 api，分别由不同操作系统的底层 api 来实现，这样对于 java 代码来说，不同操作系统的代码是一致的。  
  
![](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4d1d92c690de4ff79f3df6d46494d604~tplv-k3u1fbpfcp-watermark.image)  
  
jvm 也是通过容器的技术实现了一份代码跑在多个平台，而且 jre 提供了统一的 api，屏蔽掉了底层的差异。  
  
### node、deno  
  
node 和 deno 也是跨平台的技术，通过提供一套一致的 api，让其上的 js 代码可以跨平台。这些 api 也是不同平台各自实现的。  
  
![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/33456ad2425d46fdbfcd5f42989e61d5~tplv-k3u1fbpfcp-watermark.image)  
  
## electron  
  
electron 内置了 chromium，并为其注入了 node 的 api 和一些 GUI 相关的 api，是基于两大跨平台技术综合而成的跨平台方案。基于这些方案的组合使得 electron 支持用前端技术开发桌面端。  
  
![](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1aa023546f8c4837a9907fcca1a9be92~tplv-k3u1fbpfcp-watermark.image)  
  
  
## 跨平台方案的优缺点  
  
跨平台方案的优点很明显，就是一份代码跑在不同平台的同样的容器内，不用不同平台单独开发，节省成本。  
  
但是跨平台方案也有缺点：  
  
- 因为多了一层容器，所以性能相比直接调用系统 api 会有所下降  
  
- 为了实现多平台的一致，需要提供一套统一的 api，这套 api 有两个难题：  
     - api 怎么设计。要综合不同平台的能力，取一个合适的集合来实现。设计上有一定难度。node、deno、java 都抽象了操作系统的能力，提供了各自的跨平台 api  
   
     - 部分 api 很难做到多平台的一致性  
  
     - 当容器没有提供的能力需要扩展的时候比较麻烦，比如 js 引擎的 bridge、 jvm 的 jni、node 的 c++ addon 等都是为这个容器扩展能力的方式  
       
       
# 说说你对低代码的了解  
## 低代码究竟是什么  
  
这些年，自从 SaaS（Software-as-a-Service） 厂商 Salesforce 市值水涨船高，还和其大手笔的商业并购案，逐渐引起了国内互联网行业人的关注，习惯进行国内外产品对标的互联网圈子兴起了一股 SaaS 风潮，在后移动互联网时代下，部分人也期待 SaaS 可以成为国内互联网的一个新增长点。  
  
随着不同的用户诉求，一些系统衍生出新的形态，不同于既定的 SaaS 产品形态，用户可以通过可视化拖拽界面、表单配置等方式，快速定制出一个完整的应用，而且这一类系统基本不用编写太多的代码，即可以实现定制化应用。随着这一形态的系统越来越多，久而久之，大家就形象地称之为**”低代码”（low-code）**，另外也有人称之为 ”aPaaS“，即应用平台即服务（属于是互联网造词老技能了...）。  
  
低代码这个概念真正火热起来，还是在于这两年 Outsystems 相继完成了数轮过亿元美金的融资，估值早早地站上了十亿美金级别，成为一方独角兽。由于国内这一领域缺少体量对等的厂商，所以大家自然也在期待哪家厂商能成长为中国的 Outsystems。与此同时，国内低代码赛道上选手也渐渐进入了大家的视野，例如钉钉宜搭、即刻应用、氚云、简道云等等。  
  
  
![低代码厂商.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/360a7f2a28cd41ef8855d17aa9894123~tplv-k3u1fbpfcp-watermark.image?)  
  
（材料来源于iRearch）  
  
## 低代码系统长什么样  
  
虽然低代码平台的形态很多，但是其中的核心还是脱离不开编程思想，基本都有以下功能模块：页面搭建、数据逻辑、数据模型，在线部署和管理系统。根据不同的业务场景，具体的平台形态分化为表单/数据模型驱动、界面驱动等形态。  
  
**表单/数据模型驱动**  
  
表单/数据模型驱动是围绕数据结构来定义整个应用的形态和流程，其中表单驱动指用户通过配置表单界面，元素大多是文本输入、下拉选择器、日期选择器等组件，配置表单界面后自动生成数据模型，并基于该表单做数据及流程管理，而数据模型驱动则更复杂，需要用户进行数据建模和定义模型关系，此操作和 SQL 数据库搭建类似，配置主键、索引，类型等等，然后基于该数据表单搭建上层的管理系统。该模式比较多应用在搭建 CRM、ERP 等管理系统。  
  
  
![维格表配置界面.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/010d21e3fc854903aa3527e45fc9d511~tplv-k3u1fbpfcp-watermark.image?)  
  
（维格表配置界面）  
  
**界面驱动**  
  
界面驱动比较好理解，就是用户通过拖拽组件方式可视化搭建界面，然后配置页面的交互逻辑，比如页面的跳转、数据获取等等。这种形式大多应用在搭建通用程序的低代码平台  
  
  
![iVX配置界面.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d454333bf63b48fcb7ee73c722cdc9f6~tplv-k3u1fbpfcp-watermark.image?)  
  
（iVx配置界面）  
  
这种模式与端应用开发的套路基本一致，只是将代码编辑修改为画布拖拽和表单配置。这里举一个简单的例子，在界面按钮设置一个点击事件，事件逻辑为拉取数据。该流程就是将编程概念提取为交互表单操作，里面还是会出现入参出参字段、回调等等概念，遵循编程的思想。  
  
  
![iVX配置界面2.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/55583fbf9fd047679293dc8ba39eb191~tplv-k3u1fbpfcp-watermark.image?)  
  
当用户将应用搭建完成后，可以直接在平台上完成发布工作，然后就可以通过给出的链接访问应用（大多数低代码平台制作出来都是 web 应用）。  
  
低代码概念虽然比较新颖，但是低代码平台已经发展了很久了（Outsystems 建立于 2001 年，国内的道一云建立于 2004 年）。总体来说，经过这些年的发展探索，低代码平台的形态也趋于稳定，各家的创新也是基于面对的用户场景而做的微创新，本质上也没有跳脱出编程思想。  
  
## 低代码怎么做个性化定制  
  
这里有同学会问了，低代码平台怎么满足个性化需求？诚然，受限于低代码平台所提供的组件和逻辑配置表单，只能解决一些通用化场景，当用户的诉求超脱出这个圈圈时，是不是就无能为力了？商业公司肯定不会这么幼稚，以下简单列举搜集到的一些个性化定制的方法：  
  
1.  用户可以在平台定制的规则下录入组件  
1.  提供 API 访问数据库  
1.  生成源代码做二次开发（低代码变代码了...）  
1.  填写反馈等平台更新  
  
  
![低代码个性化定制.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f5a37e4a16d64143b5e51ebdfd63ecc6~tplv-k3u1fbpfcp-watermark.image?)  
  
除了这些固定的章程，低代码厂商还有工程师群体，当用户登录到低代码平台，立即就有专人跟进，询问诉求等等，后续可以根据用户诉求给出合适的配置方案，乃至专门定制个性化场景。到这里就闻到了一丝外包的气味，不过这确实是一个可以带来收入的场景。  
  
## 低代码有没有用？  
  
“低代码究竟有没有用？”  
  
这个问题浮现在各个论坛上。这个问题可以理解为低代码的声量和其能力不匹配，用户对低代码信心不足。对于目前低代码平台的问题，存在主观和客观的因素。  
  
首先很多**低代码平台能力还没有足够完善成熟**，这是一个很核心的因素。对于很多初次使用的用户来说，概念繁多，逻辑复杂，在一番体验以后，预期和实际有落差。使用起来总体耗时跟源码开发相差无几，显得工具比较鸡肋。客观上，国内的人力资源情况相比欧美还是比较便宜，很多有定制应用诉求的客户，首先会想到的是找外包，或者招聘开发岗位，而不是找低代码工具自己动手。另外大家对于低代码的认知也还不足，很难成为一个备选项。  
  
思考这个问题，我们想一个简单问题，“一个可以降低门槛，提高效率的工具有没有用”，答案很显然是肯定的。**低代码平台的宗旨，不就是“降低门槛”，“降本增效”么。**  
  
个人觉得，这些问题大概是时间的问题。就目前市面上的低代码工具而言，从实际需求出发，当深入体验过以后，其实是可以深切感受到工具带来的红利。花上几天，一个人就可以实现前后端应用，以及运维监控，拿到一套可运行的程序。  
  
随着行业关注度的提升和资源的投入，上述遇到的问题大多可以得到解决。**低代码从“可用”到“好用”的进化，也是需要在实际场景中摸爬滚打中历练进化**。  
  
## 目前低代码发展状况  
  
前面说了，低代码的热度持续提升，最明显的举动就是资本真金白银的投资。  
  
![融资情况.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/883a238b0b344f319ab2917ace625167~tplv-k3u1fbpfcp-watermark.image?)  
（材料来源于iResearch）  
  
另外有一个举动也很巧妙。钉钉发布了一个低代码聚合平台，宜搭、氚云、简道云、易鲸云等头部低代码厂商入驻。钉钉拥有国内最大的商务用户人群，而低代码在国内比较成功的落地场景是定制企业管理系统（例如 CRM），**将低代码平台对接到巨大的对口流量之上**，这种契合的操作颇有几分微信接入微信支付一般痛快。  
  
虽然目前发展势头不错，但是打铁还需自身硬，避免共享经济那样一地鸡毛。低代码只有切实地把门槛降低、降本增效目标落在产品上，才可以长久地生存下去。  
  
# 怎么实现样式隔离？  
> 本文主要讲css各种解决方案，包括，`BEM`、`css modules`、`Css in Js`、`预处理器`、`Shadow DOM`，`Vue Scoped`通过分析各项方案的**产生背景、带来的好处以及存在的一些问题**来帮助大家判断自己的`项目中适合使用哪种那方案`  
  
![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7db1aa96587544189fe051561fbebef4~tplv-k3u1fbpfcp-watermark.image?)  
  
![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ed3cf9e346434949b63c5d1e4b02c38b~tplv-k3u1fbpfcp-watermark.image?)  
  
## 零：CSS的原生问题  
在讲解各种解决方案之前，我们先回顾下日常开发中我们遇到的css问题，待着这些问题，我们在讲解各种解决方案，并分析各个解决方案是否可以解决如下问题  
### 0.1 无作用域样式污染  
CSS有一个被大家诟病的问题就是`没有本地作用域`，所有声明的样式都是`全局的（global styles）`  
  
换句话来说页面上任意元素只要匹配上某个选择器的规则，这个规则就会被应用上，而且规则和规则之间可以`叠加作用（cascading）`  
  
`SPA应用`流行了之后这个问题变得更加突出了，因为对于SPA应用来说所有页面的样式代码都会加载到同一个环境中，样式冲突的概率会大大加大。由于这个问题的存在，我们在日常开发中会遇到以下这些问题：  
  
- **很难为选择器起名字**：为了避免和页面上其他元素的样式发生冲突，我们在起选择器名的时候一定要深思熟虑，起的名字一定不能太普通。举个例子，假如你为页面上某个作为标题的DOM节点定义一个叫做`.title`的样式名，这个类名很大概率已经或者将会和页面上的其他选择器发生冲突，所以你不得不**手动**为这个类名添加一些前缀，例如`.home-page-title`来避免这个问题  
- **团队多人合作困难**：当多个人一起开发同一个项目的时候，特别是多个分支同时开发的时候，大家各自取的选择器名字可能有会冲突，可是在本地独立开发的时候这个问题几乎发现不了。当大家的代码合并到同一个分支的时候，一些样式的问题就会随之出现  
  
### 0.2 无用的CSS样式堆积  
进行过大型Web项目开发的同学应该都有经历过这个情景：在开发新的功能或者进行代码重构的时候，由于`HTML代码和CSS样式之间没有显式的一一对应关系`，我们很难辨认出项目中哪些CSS样式代码是有用的哪些是无用的，这就导致了我们不敢轻易删除代码中可能是无用的样式。这样随着时间的推移，项目中的CSS样式只会增加而不会减少([append-only stylesheets](https://link.zhihu.com/?target=https%3A//css-tricks.com/oh-no-stylesheet-grows-grows-grows-append-stylesheet-problem/)）。无用的样式代码堆积会导致以下这些问题：  
  
- **项目变得越来越重量级**：加载到浏览器的CSS样式会越来越多，会造成一定的性能影响  
- **开发成本越来越高**：开发者发现他们很难理解项目中的样式代码，甚至可能被大量的样式代码吓到，这就导致了开发效率的降低以及一些奇奇怪怪的样式问题的出现  
  
### 0.3 基于状态的样式定义  
对于SPA应用来说，特别是一些交互复杂的页面，页面的样式通常要根据组件的状态变化而发生变化  
  
最常用的方式是通过不同的状态定义不同的`className名`，这种方案代码看起来十分冗余和繁琐，通常需要同时改动`js代码和css代码`  
  
> `这个CSS重写一遍比修改老文件快`，这样的念头几乎所有人都曾有过，css虽然看似简单，但是以上问题很容易写着写着就出现了，这在于提前没有选好方案  
  
  
## 一、BEM  
### 1.1 简介  
BEM是`一种css命名方法论`，意思是块（Block）、元素（Element）、修饰符（Modifier）的简写  
  
这种命名方法让[CSS](https://baike.baidu.com/item/CSS/5457)便于统一团队开发规范和方便维护  
  
以 `.block__element--modifier`或者说`block-name__element-name--modifier-name`形式命名，命名有含义，也就是`模块名 + 元素名 + 修饰器名`  
  
如`.dropdown-menu__item--active`  
  
社区里面对BEM命名的褒贬不一，但是对其的思想基本上还是认同的，所以可以`用它的思想，不一定要用它的命名方式`  
  
### 1.2 应用场景  
BEM思想通常用于`组件库`，业务代码中`结合less等预处理器`  
  
### 1.3 优缺点分析  
#### 优点：  
1. 人为严格遵守BEM规范，可以解决无作用域样式污染问题  
2. 可读性好，一目了然是那个dom节点，对于无用css删除，删除了相应dom节点后，对应的css也能比较放心的删除，不会影响到其他元素样式  
#### 缺点  
1. 命名太长（个人开发习惯、部分人会觉得，我认为命名长提高了可读性，能解决一些问题，也不叫缺点），至于体积增大，gzip可忽略  
  
> 个人比较喜欢BEM，其思想对编码好处远大于坏处，有兴趣的可以在项目中使用，更多可看[知乎：如何看待 CSS 中 BEM 的命名方式？](https://www.zhihu.com/question/21935157)  
  
## 二、CSS modules  
### 2.1 简介  
什么是`CSS Modules`？  
  
顾名思义，`css-modules 将 css 代码模块化`，可以避免`本模块样式被污染`，并且可以很方便的复用 css 代码  
  
根据`CSS Modules`在Gihub上的[项目](https://github.com/css-modules/css-modules)，它被解释为：  
  
> 所有的类名和动画名称默认都有各自的作用域的CSS文件。  
  
所以`CSS Modules`既不是官方标准，也不是浏览器的特性，而是**在构建步骤（例如使用Webpack，记住css-loader）中对CSS类名和选择器`限定作用域`的一种方式**（类似于命名空间）  
  
依赖`webpack css-loader`，配置如下，现在webpack已经默认开启CSS modules功能了  
```js  
{  
    test: /.css$/,  
    loader: "style-loader!css-loader?modules"  
}  
```  
  
我们先看一个示例：  
  
将`CSS`文件`style.css`引入为`style`对象后，通过`style.title`的方式使用`title class`：  
  
```jsx  
import style from './style.css';  
  
export default () => {  
  return (  
    <p className={style.title}>  
      I am KaSong.  
    </p>  
  );  
};  
```  
  
对应`style.css`：  
  
```css  
.title {  
  color: red;  
}  
```  
打包工具会将`style.title`编译为`带哈希的字符串`  
```jsx  
<h1 class="_3zyde4l1yATCOkgn-DBWEL">  
  Hello World  
</h1>  
```  
同时`style.css`也会编译：  
```css  
._3zyde4l1yATCOkgn-DBWEL {  
  color: red;  
}  
```  
  
这样，就产生了独一无二的`class`，解决了`CSS`模块化的问题  
  
使用了 CSS Modules 后，就相当于给每个 class 名外加加了一个 `:local`，以此来实现样式的局部化，如果你想切换到全局模式，使用对应的 `:global`。  
  
`:local` 与 `:global` 的区别是 CSS Modules 只会对 `:local` 块的 class 样式做 `localIdentName` 规则处理，`:global` 的样式编译后不变  
```css  
.title {  
  color: red;  
}  
  
:global(.title) {  
  color: green;  
}  
```  
可以看到，依旧使用CSS，但使用JS来管理样式依赖，  
最大化地结合现有 CSS 生态和 JS 模块化能力，发布时依旧编译出单独的 JS 和 CSS  
  
### 2.2 优缺点分析  
#### 优点  
- 能100%解决css无作用域样式污染问题  
- 学习成本低：API简洁到几乎零学习成本  
#### 缺点  
- 写法没有传统开发流程，如果你不想频繁的输入 `styles.**`，可以试一下 [react-css-modules]([gajus/react-css-modules · GitHub](https://link.zhihu.com/?target=https%3A//github.com/gajus/react-css-modules))，它通过高阶函数的形式来避免重复输入 `styles.**`  
- 没有变量，通常要结合预处理器  
- 代码可读性差，hash值不方便debug  
  
> css modules通常结合less等预处理器在react中使用，更多可参考[CSS Modules 详解及 React 中实践](https://zhuanlan.zhihu.com/p/20495964)  
  
## 三、CSS in JS  
  
### 3.1 简介  
`CSS in JS`是2014年推出的一种**设计模式**，它的核心思想是`把CSS直接写到各自组件中`，也就是说`用JS去写CSS`，而不是单独的样式文件里  
  
这跟传统的前端开发思维不一样，传统的原则是`关注点分离`，如常说的`不写行内样式`、`不写行内脚本`，如下代码  
```html  
<h1 style="color:red;font-size:46px;"  onclick="alert('Hi')">  
  Hello World  
</h1>  
```  
  
`CSS-in-JS`不是一种很新的技术，可是它在国内普及度好像并不是很高，它当初的出现是因为一些`component-based`的`Web`框架（例如 `React`，`Vue` 和 `Angular`）的逐渐流行，使得开发者也想`将组件的CSS样式也一块封装到组件中去`以**解决原生CSS写法的一系列问题**  
  
>CSS-in-JS在`React社区`的热度是最高的，这是因为React本身不会管用户怎么去为组件定义样式的问题，而Vue和Angular都有属于框架自己的一套定义样式的方案  
  
上面的例子使用 `React` 改写如下  
  
```jsx  
const style = {  
  'color': 'red',  
  'fontSize': '46px'  
};  
  
const clickHandler = () => alert('hi');   
  
ReactDOM.render(  
  <h1 style={style} onclick={clickHandler}>  
     Hello, world!  
  </h1>,  
  document.getElementById('example')  
);  
```  
上面代码在一个文件里面，封装了**结构、样式和逻辑**，完全`违背了"关注点分离"的原则`  
  
但是，这`有利于组件的隔离`。每个组件包含了所有需要用到的代码，不依赖外部，组件之间没有耦合，很方便复用。所以，随着 React 的走红和组件模式深入人心，这种"`关注点混合`"的新写法逐渐成为主流  
  
### 3.2 实现CSS in JS的库汇总  
实现了`CSS-in-JS`的库有很多，[据统计](https://link.zhihu.com/?target=https%3A//github.com/MicheleBertoli/css-in-js)现在已经超过了61种。虽然每个库解决的问题都差不多，可是它们的实现方法和语法却大相径庭  
  
从实现方法上区分大体分为两种：  
- `唯一CSS选择器`，代表库：[styled-components](https://github.com/styled-components/styled-components)  
- `内联样式`（Unique Selector VS Inline Styles）  
  
不同的`CSS in JS`实现除了生成的`CSS样式和编写语法`有所区别外，它们实现的功能也不尽相同，除了一些最基本的诸如CSS局部作用域的功能，下面这些功能有的实现会包含而有的却不支持：  
-   自动生成浏览器引擎前缀 - built-in vendor prefix  
-   支持抽取独立的CSS样式表 - extract css file  
-   自带支持动画 - built-in support for animations  
-   伪类 - pseudo classes  
-   媒体查询 - media query  
-   其他  
  
  
### 3.3 [styled-components](https://github.com/styled-components/styled-components)示例  
[Styled-components](https://github.com/styled-components/styled-components) 是`CSS in JS`最热门的一个库了，到目前为止github的star数已经超过了`35k`  
  
通过`styled-components`，可以使用ES6的[标签模板字符串](https://link.zhihu.com/?target=https%3A//developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals)语法（Tagged Templates）为需要`styled`的`Component`定义一系列`CSS`属性  
  
当该组件的`JS代码被解析执行`的时候，`styled-components会动态生成一个CSS选择器`，并把对应的`CSS`样式通过`style`标签的形式插入到`head`标签里面。动态生成的`CSS`选择器会有一小段`哈希值来保证全局唯一性`来避免样式发生冲突  
  
[CSS-in-JS Playground](https://link.zhihu.com/?target=https%3A//www.cssinjsplayground.com/)是一个可以快速尝试不同CSS-in-JS实现的网站，上面有一个简单的用`styled-components`实现表单的例子：  
![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cc1c95acd5ff4b87b0d3a97326510b45~tplv-k3u1fbpfcp-watermark.image?)  
  
从上面的例子可以看出，`styled-components`不需要你为需要设置样式的DOM节点设置一个`样式名`，使用完标签模板字符串定义后你会得到一个`styled`好的`Component`，直接在`JSX`中使用这个`Component`就可以了  
  
![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c65d76ba48234451a0b22e15f6bdd4c2~tplv-k3u1fbpfcp-watermark.image?)  
可以看到截图里面框出来的样式生成了一段`hash值`，实现了`局部CSS作用域`的效果（scoping styles），`各个组件的样式不会发生冲突`  
  
### 3.4 [Radium](https://formidable.com/open-source/radium/)示例  
`Radium`和`styled-components`的最大区别是它生成的是`标签内联样式（inline styles）`  
  
由于标签内联样式在处理诸如`media query`以及`:hover`，`:focus`，`:active`等和浏览器状态相关的样式的时候非常不方便，所以`radium`为这些样式封装了一些标准的接口以及抽象  
  
再来看一下`radium`在[CSS-in-JS Playground](https://www.cssinjsplayground.com/?activeModule=index&library=radium)的例子：  
  
![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/668ec69c9681461face360b8afbd96cd~tplv-k3u1fbpfcp-watermark.image?)  
从上面的例子可以看出`radium`定义样式的语法和`styled-components`有很大的区别，它要求你使用`style`属性为`DOM`添加相应的样式  
  
直接在标签内生成内联样式，内联样式相比于CSS选择器的方法有以下的优点： `自带局部样式作用域的效果`，无需额外的操作  
  
### 3.5 CSS in JS 与"CSS 预处理器"（比如 Less 和 [Sass](https://www.ruanyifeng.com/blog/2012/06/sass.html)，包括 PostCSS）有什么区别  
`CSS in JS` 使用 `JavaScript` 的语法，**是 JavaScript 脚本的一部分**，不用从头学习一套专用的 API，也不会多一道编译步骤，但是通常会在运行时动态生成CSS，造成一定运行时开销  
  
### 3.6 优缺点分析  
#### 优点  
- **没有无作用域问题样式污染问题**  
      
    通过唯一CSS选择器或者行内样式解决  
- **没有无用的CSS样式堆积问题**  
      
    CSS-in-JS会把样式和组件绑定在一起，当这个组件要被删除掉的时候，直接把这些代码删除掉就好了，不用担心删掉的样式代码会对项目的其他组件样式产生影响。而且由于CSS是写在JavaScript里面的，我们还可以利用JS显式的变量定义，模块引用等语言特性来追踪样式的使用情况，这大大方便了我们对样式代码的更改或者重构  
      
- **更好的基于状态的样式定义**  
  
    CSS-in-JS会直接将CSS样式写在JS文件里面，所以样式复用以及逻辑判断都十分方便  
  
#### 缺点：  
- **一定的学习成本**  
- **代码可读性差**  
      
    大多数CSS-in-JS实现会通过生成唯一的CSS选择器来达到CSS局部作用域的效果。这些自动生成的选择器会大大降低代码的可读性，给开发人员debug造成一定的影响  
- **运行时消耗**  
  
    由于大多数的CSS-in-JS的库都是在动态生成CSS的。这会有两方面的影响。首先你发送到客户端的代码会包括使用到的CSS-in-JS运行时（runtime）代码，这些代码一般都不是很小，例如styled-components的runtime大小是`12.42kB min + gzip`，如果你希望你首屏加载的代码很小，你得考虑这个问题。其次大多数CSS-in-JS实现都是在客户端动态生成CSS的，这就意味着会有一定的性能代价。不同的CSS-in-JS实现由于具体的实现细节不一样，所以它们的性能也会有很大的区别，你可以通过[这个工具](https://link.zhihu.com/?target=http%3A//necolas.github.io/react-native-web/benchmarks/)来查看和衡量各个实现的性能差异  
      
- 不能结合成熟的CSS预处理器（或后处理器）Sass/Less/PostCSS，`:hover` 和 `:active` 伪类处理起来复杂  
      
> 可以看到优点多，缺点也不少，选择需慎重，更多可阅读阮一峰老师写的[CSS in JS简介](http://www.ruanyifeng.com/blog/2017/04/css_in_js.html)，[知乎CSS in JS的好与坏](https://zhuanlan.zhihu.com/p/103522819)  
## 四、预处理器  
### 4.1 简介  
**CSS 预处理器**是一个能让你通过预处理器自己独有的语法的程序  
  
市面上有很多CSS预处理器可供选择，且绝大多数CSS预处理器**会增加一些原生CSS不具备的特性**，例如  
- 代码混合  
- 嵌套选择器  
- 继承选择器  
  
这些特性让CSS的结构`更加具有可读性且易于维护`  
  
要使用CSS预处理器，你必须在web服务中安装CSS`编译工具`  
  
我们常见的预处理器：  
-   [Sass](https://sass-lang.com/)  
-   [LESS](https://lesscss.org/)  
-   [Stylus](http://stylus-lang.com/)  
-   [PostCSS](http://postcss.org/)  
  
### 4.2 优缺点分析  
  
#### 优点：  
1. 利用嵌套，人为严格遵守嵌套首类名不一致，可以解决无作用域样式污染问题  
2. 可读性好，一目了然是那个dom节点，对于无用css删除，删除了相应dom节点后，对应的css也能比较放心的删除，不会影响到其他元素样式  
#### 缺点  
1. 需要借助相关的编译工具处理  
  
> 预处理器是现代web开发中必备，`结合BEM规范`，利用预处理器，可以极大的`提高开发效率，可读性，复用性`  
  
## 五、Shadow DOM  
### 5.1 简介  
熟悉`web Components`的一定知道`Shadow DOM`可以实现样式隔离，由浏览器原生支持  
![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a0444ea0c1ab4d54b6552f4f4d559bd0~tplv-k3u1fbpfcp-watermark.image?)  
  
我们经常在微前端领域看到`Shadow DOM`，如下创建一个子应用  
```js  
const shadow = document.querySelector('#hostElement').attachShadow({mode: 'open'});  
shadow.innerHTML = '<sub-app>Here is some new text</sub-app><link rel="stylesheet" href="//unpkg.com/antd/antd.min.css">';  
```  
  
由于子应用的样式作用域仅在 `shadow` 元素下，那么一旦子应用中出现运行时越界跑到外面构建 DOM 的场景，必定会导致构建出来的 DOM 无法应用子应用的样式的情况。  
  
比如 `sub-app` 里调用了 `antd modal` 组件，由于 `modal` 是动态挂载到 `document.body` 的，而由于 `Shadow DOM` 的特性 `antd` 的样式只会在 `shadow` 这个作用域下生效，结果就是弹出框无法应用到 `antd` 的样式。解决的办法是把 `antd` 样式上浮一层，丢到主文档里，但这么做意味着子应用的样式直接泄露到主文档了  
  
  
### 5.2 优缺点分析  
#### 优点  
- 浏览器原生支持  
- 严格意义上的样式隔离，如iframe一样  
#### 缺点  
- 浏览器兼容问题  
- 只对一定范围内的dom结构起作用，上面微前端场景已经说明  
  
> 普通业务开发我们还是用框架、如Vue、React；Shadow DOM适用于特殊场景，如微前端  
  
  
  
  
  
  
## 六、vue scoped  
当 `<style>` 标签有 `scoped` 属性时，它的 `CSS` 只作用于当前组件中的元素  
  
通过使用 `PostCSS` 来实现以下转换：  
  
```html  
<style scoped>  
.example {  
  color: red;  
}  
</style>  
  
<template>  
  <div class="example">hi</div>  
</template>  
```  
转换结果：  
```html  
<style>  
.example[data-v-f3f3eg9] {  
  color: red;  
}  
</style>  
  
<template>  
  <div class="example" data-v-f3f3eg9>hi</div>  
</template>  
```  
使用 `scoped` 后，**父组件的样式将不会渗透到子组件中**  
  
不过一个子组件的根节点会同时受其父组件的 scoped CSS 和子组件的 scoped CSS 的影响。这样设计是为了让父组件可以从布局的角度出发，调整其子组件根元素的样式，父租价利用`深度作用选择器`影响子组件样式  
  
可以使用 `>>>` 操作符：  
```html  
<style scoped>  
.a >>> .b { /* ... */ }  
</style>  
```  
上述代码将会编译成：  
  
```html  
.a[data-v-f3f3eg9] .b { /* ... */ }  
```  
有些像 `Sass` 之类的预处理器无法正确解析 `>>>`。这种情况下你可以使用 `/deep/` 或 `::v-deep` 操作符取而代之——两者都是 `>>>` 的别名，同样可以正常工作  
  
  
## 总结  
  
六种方案对比如下，社区通常的样式隔离方案，以下两种  
- `BEM+预处理器`  
- `CSS Moduls + 预处理器`  
![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ed3cf9e346434949b63c5d1e4b02c38b~tplv-k3u1fbpfcp-watermark.image?)  
  
  
# 为什么推荐将静态资源放到cdn上？  
## 静态资源是什么  
  
### 静态资源  
  
静态资源是指在不同请求中访问到的数据都相同的静态文件。例如：图片、视频、网站中的文件（html、css、js）、软件安装包、apk文件、压缩包文件等。  
  
### 动态资源  
动态资源是指在不同请求中访问到的数据不相同的动态内容。例如：网站中的文件（asp、jsp、php、perl、cgi）、API接口、数据库交互请求等。  
  
## CDN是什么  
内容分发网络，Content Delivery Network或Content Ddistribute Network，简称CDN，是建立并覆盖在承载网之上，由分布在不同区域的边缘节点服务器群组成的分布式网络。  
  
**CDN加速的本质是缓存加速**。将服务器上存储的静态内容缓存在CDN节点上，当访问这些静态内容时，无需访问服务器源站，就近访问CDN节点即可获取相同内容，从而达到加速的效果，同时减轻服务器源站的压力。  
  
CDN应用广泛，解决因分布、带宽、服务器性能带来的访问延迟问题，适用于站点加速、点播、直播等场景。使用户可就近取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度和成功率。  
  
  
由于访问动态内容时，每次都需要访问服务器，由服务器动态生成实时的数据并返回。因此CDN的缓存加速不适用于加速动态内容，CDN无法缓存实时变化的动态内容。对于动态内容请求，CDN节点只能转发回服务器源站，没有加速效果。  
  
## CDN的作用  
  
**1. 加速网站的访问**  
  
**2. 为了实现跨运营商、跨地域的全网覆盖**  
  
互联不互通、区域ISP地域局限、出口带宽受限制等种种因素都造成了网站的区域性无法访问。CDN加速可以覆盖全球的线路，通过和运营商合作，部署IDC资源，在全国骨干节点商，合理部署CDN边缘分发存储节点，充分利用带宽资源，平衡源站流量。  
  
**3. 为了保障你的网站安全**  
  
CDN的负载均衡和分布式存储技术，可以加强网站的可靠性，相当无无形中给你的网站添加了一把保护伞，应对绝大部分的互联网攻击事件。防攻击系统也能避免网站遭到恶意攻击。  
  
**4. 为了异地备援**  
  
当某个服务器发生意外故障时，系统将会调用其他临近的健康服务器节点进行服务，进而提供接近100%的可靠性，这就让你的网站可以做到永不宕机。  
  
**5. 为了节约成本投入**  
  
使用CDN加速可以实现网站的全国铺设，你根据不用考虑购买服务器与后续的托管运维，服务器之间镜像同步，也不用为了管理维护技术人员而烦恼，节省了人力、精力和财力。  
  
**6. 为了让你更专注业务本身**  
  
CDN加速厂商一般都会提供一站式服务，业务不仅限于CDN，还有配套的云存储、大数据服务、视频云服务等，而且一般会提供7x24运维监控支持，保证网络随时畅通，你可以放心使用。并且将更多的精力投入到发展自身的核心业务之上。  
  
  
  
## CDN工作原理  
![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f8402497bd0349aaac7825a2335eb72b~tplv-k3u1fbpfcp-watermark.image)  
  
* 当用户点击网站页面上的内容URL，经过本地DNS系统解析，DNS系统会最终将域名的解析权交给CNAME指向的CDN专用DNS服务器。  
* CDN的DNS服务器将CDN的全局负载均衡设备IP地址返回用户。  
* 用户向CDN的全局负载均衡设备发起内容URL访问请求。  
* CDN全局负载均衡设备根据用户IP地址，以及用户请求的内容URL，选择一台用户所属区域的区域负载均衡设备，告诉用户向这台设备发起请求。  
* 区域负载均衡设备会为用户选择一台合适的缓存服务器提供服务，选择的依据包括：根据用户IP地址，判断哪一台服务器距用户最近；根据用户所请求的URL中携带的内容名称，判断哪一台服务器上有用户所需内容；查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。基于以上这些条件的综合分析之后，区域负载均衡设备会向全局负载均衡设备返回一台缓存服务器的IP地址。  
* 全局负载均衡设备把服务器的IP地址返回给用户。  
* 用户向缓存服务器发起请求，缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上并没有用户想要的内容，而区域均衡设备依然将它分配给了用户，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器将内容拉到本地。  
  
DNS服务器根据用户IP地址，将域名解析成相应节点的缓存服务器IP地址，实现用户就近访问。使用CDN服务的网站，只需将其域名解析权交给CDN的GSLB设备，将需要分发的内容注入CDN，就可以实现内容加速了。  
  
## 当没有CDN时  
  
今天我们看到的网站系统基本上都是基于B/S架构的。B/S架构，即Browser-Server（浏览器 服务器）架构。  
  
用户通过浏览器等方式访问网站的过程：  
  
* 用户在自己的浏览器中输入要访问的网站域名。  
* 浏览器向本地DNS服务器请求对该域名的解析。  
* 本地DNS服务器中如果缓存有这个域名的解析结果，则直接响应用户的解析请求。  
* 本地DNS服务器中如果没有关于这个域名的解析结果的缓存，则以递归方式向整个DNS系统请求解析，获得应答后将结果反馈给浏览器。  
* 浏览器得到域名解析结果，就是该域名相应的服务设备的IP地址。  
* 浏览器向服务器请求内容。  
* 服务器将用户请求内容传送给浏览器。  
# npm 和 yarn有哪些不一样的地方？  
## 早期的npm  
  
其实在最早期的`npm`版本(npm v2)，`npm`的设计可以说是非常的简单，在安装依赖的时候会将依赖放到 `node_modules`文件中。同时，如果某个直接依赖A依赖于其他的依赖包B，那么依赖B会作为间接依赖，安装到依赖A的文件夹`node_modules`中，然后可能多个包之间也会有出现同样的依赖递归的，如果项目一旦过大,那么必然会形成一棵巨大的依赖树，依赖包会出现重复，形成`嵌套地狱`。  
  
那么我们如何去理解"嵌套地狱"呢？  
  
- 首先,项目的依赖树的层级过于深，如果有问题不利于排查和调试  
- 在依赖的分支中,可能会出现同样版本的相互依赖的问题  
  
那么这样的重复问题会带来什么后果呢？  
  
- 首先,会使得安装的结果占据了大量的空间资源,造成了资源的浪费  
- 同时,因为安装的依赖重复,会造成在安装依赖时,安装时间过长  
- 甚至是,因为目录层级过深,导致文件路径过长,会在`windows`系统下删除`node_modules`文件,出现删除不掉的情况  
  
那么, 后面的版本是如何一步步进行优化的呢？后面会陆续的揭晓。  
  
  
## npm or yarn 开发中的一点疑惑  
  
你在实际的开发会不会出现这样的一些情况：  
  
1. 当你项目依赖出现问题的时候，我们会不会是直接删除 `node_modules 和 lockfiles`依赖，再重新 `npm install`，删除大法是否真的好用？这样的使用方案会不会带来什么问题？  
2. 把所有的依赖包都安装到`dependencies`中，对`devDependencies` 不区分会不会有问题?  
3. 一个项目中，你使用 `yarn`，我使用`npm`，会不会有问题呢？  
4. 还有一个问题，`lockfiles 文件` 我们提交代码的时候需不需要提交到仓库中呢？  
  
## npm的安装机制和核心原理  
  
我们可以先来看看 npm 的核心目标  
  
> Bring the best of open source to you, your team and your company.  
  
意思是 给你和你的团队、你的公司带来最好的开源库和依赖。 通过这句话,我们可以了解到 npm 最重要的一点就是安装和维护依赖。那么，让我们先来看一看`npm`的安装机制是怎样的呢？  
  
### npm的安装机制  
  
下面我们会通过一个流程图来具体学习`npm install`的安装机制  
  
![](https://ae04.alicdn.com/kf/H5f7e9047bb794016a6464c7b93f79938p.png)  
  
`npm install`执行之后，首先会检查和获取 `npm的配置`，这里的优先级为：  
  
`项目级的.npmrc文件 > 用户级的 .npmrc文件 > 全局级的 .npmrc > npm内置的 .npmrc 文件`  
  
然后检查项目中是否有 `package-lock.json`文件  
  
- 如果有，检查 `package-lock.json`和 `package.json`声明的依赖是否一致：  
    
  - 一致。直接使用`package-lock.json`中的信息,从网络或者缓存中加载依赖。  
  - 不一致。根据上述流程中的不同版本进行处理。  
- 如果没有，那么会根据`package.json`递归构建依赖树，然后就会根据构建好的依赖去下载完整的依赖资源，在下载的时候，会检查有没有相关的资源缓存：  
    
  - 存在。直接解压到`node_modules`文件中。  
  - 不存在。从npm远端仓库下载包，校验包的完整性，同时添加到缓存中，解压到 `node_modules`中。  
  
最后，生成 `package-lock.json` 文件。  
  
其实，在我们实际的项目开发中，使用npm作为团队的最佳实践: `同一个项目团队，应该保持npm 版本的一致性`。  
  
从上面的安装流程，不知道大家注意到了一点没有，在实际的项目开发中，如果每次都去安装对应依赖时，如果相关的依赖包体积过大或者是依赖于网络，无疑会增加安装的时间成本。那么，缓存在这里的就是一个解决问题的好办法。  
  
## yarn的出现  
  
yarn 是一个由`Facebook`、`Google`、`Exponent`和`Tilde`构建的新的JavaScript包管理器。它的出现是为了解决历史上`npm`的某些不足(比如npm对于依赖的完整性和一致性的保证,以及npm安装过程中速度很慢的问题)  
  
当npm还处于`v3`时期的时候，一个叫`yarn`的包管理工具横空出世。在2016年，npm还没有package-lock.json文件，安装的时候速度很慢，稳定性很差，`yarn`的出现很好的解决了一下的一些问题：  
  
- **确定性:** 通过yarn.lock等机制，即使是不同的安装顺序，相同的依赖关系在任何的环境和容器中，都可以以相同的方式安装。(那么,此时的npm v5之前,并没有package-lock.json机制，只有默认并不会使用 npm-shrinkwrap.json)  
    
- **采用模块扁平化的安装模式:** 将不同版本的依赖包，按照一定的策略，归结为单个版本。以避免创建多个版本造成工程的冗余(目前的npm也有相同的优化)  
    
- **网络性能更好:** `yarn`采用了请求排队的理念，类似于并发池连接，能够更好的利用网络资源；同时也引入了一种安装失败的重试机制。  
    
- **采用缓存机制，实现了离线模式** (目前的npm也有类似的实现)  
    
  
我们可以来看一下 `yarn.lock`的结构：  
  
```  
"@babel/cli@^7.1.6", "@babel/cli@^7.5.5":  
  version "7.8.4"  
  resolved "http://npm.in.zhihu.com/@babel%2fcli/-/cli-7.8.4.tgz#505fb053721a98777b2b175323ea4f090b7d3c1c"  
  integrity sha1-UF+wU3IamHd7KxdTI+pPCQt9PBw=  
  dependencies:  
    commander "^4.0.1"  
    convert-source-map "^1.1.0"  
    fs-readdir-recursive "^1.1.0"  
    glob "^7.0.0"  
    lodash "^4.17.13"  
    make-dir "^2.1.0"  
    slash "^2.0.0"  
    source-map "^0.5.0"  
  optionalDependencies:  
    chokidar "^2.1.8"  
```  
  
熟悉npm的`package-lock.json`文件的朋友，可能一眼就看到了一些不同; `package-lock.json`采用的是`JSON`的结构，而`yarn`并没有采用这种结构，而是一种自定义的标记方式;我们可以看出新的自定义的方式，也同样保持了高度的可读性。  
  
**相比于npm,Yarn另一个显著的区别就是yarn.lock的子依赖的版本不是固定的版本**。这其实就说明了一个问题：一个单独的`yarn.lock`的问题并不能确定`node_modules`的文件结构，还需要`package.json`的配合。  
  
### yarn的安装机制  
  
上面一小节我们对npm的安装机制有了一些基本的了解,现在让我们先来简单的看一下`Yarn`的安装理念。  
  
简单来说, `Yarn`的安装大致分为5个步骤：  
  
![](https://ae01.alicdn.com/kf/H6a301654aeb54b1ebe0d58ceed2280a28.png)  
  
检测(checking) ---> 解析包(Resolving Packages) ---> 获取包(Fetching) ---> 链接包(Linking Packages) ---> 构建包(Building Packages)  
  
那么接下来我们要开始具体分析这些过程中都做了哪些事情:  
  
**检测包**  
  
这一步，最主要的目的就是检测我们的项目中是否存在npm相关的文件,比如`package-lock.json`等;如果有,就会有相关的提示用户注意：这些文件可能会存在冲突。在这一步骤中  
也会检测系统OS, CPU等信息。  
  
**解析包**  
  
这一步会解析依赖树中的每一个包的信息:  
  
首先呢,获取到`首层依赖`: 也就是我们当前所处的项目中的`package.json`定义的`dependencies`、`devDependencies`、`optionalDependencies`的内容。  
  
紧接着**会采用遍历首层依赖的方式来获取包的依赖信息**,以及递归查找每个依赖下嵌套依赖的版本信息，并将解析过的包和正在进行解析包呢`用Set数据结构进行存储`,这样就可以保证`同一版本范围内的包`不会进行重复的解析:  
  
- 对于没有解析过的包A, 首次尝试从 `yarn.lock`中获取版本信息,并且标记为已解析  
- 如果在`yarn.lock`中没有找到包A， 则向`Registry`发起请求获取满足版本范围内的已知的最高版本的包信息,获取之后将该包标记为已解析。  
  
总之，经过解析包这一步之后呢,我们就已经确定了解析包的具体版本信息和包的下载地址。  
  
![](https://ae03.alicdn.com/kf/Heea67a28e5cb49aa91e2e7aa4adc0f501.png)  
  
**获取包**  
  
这一步首先我们会检查缓存中是否有当前依赖的包,同时呢将缓存中不存在的包下载到缓存的目录中。但是这里有一个小问题需要大家思考一下:  
  
比如: 如何去判断缓存中有当前的依赖包呢？  
  
**其实呢,在Yarn中会根据 cacheFolder+[slug](https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2FTrott%2Fslug "https://github.com/Trott/slug")+node_modules+pkg.name 生成一个路径;判断系统中是否存在该path,如果存在证明已经有缓存,不用重新下载。这个path也就是依赖包缓存的具体路径。**  
  
那么对于没有命中的缓存包呢？在 `Yarn` 中存在一个Fetch队列,按照具体的规则进行网络请求。如果下载的包是一个file协议,或者是相对路径,就说明指向一个本地目录,此时会调用Fetch From Local从离线缓存中获取包;否则调用 Fetch From External 获取包,最终获取的结果使用 fs.createWriteStream 写入到缓存目录。  
  
![](https://ae03.alicdn.com/kf/H68e74a66cd20480b8cf42ef5a5b55c5fD.png)  
  
**链接包**  
  
我们上一步已经把依赖放到了缓存目录,那么下一步,我们应该要做什么事情呢？是不是应该把项目中的依赖复制到`node_modules`目录下呢,没错;只不过此时需要遵循一个扁平化的原则。复制依赖之前, `Yarn`会先解析 `peerDepdencies`，如果找不到符合要求的`peerDepdencies`的包,会有 `warning`提示，并最终拷贝依赖到项目中。  
  
![imagepng](https://ae01.alicdn.com/kf/H6aae377c6c0340eab0b429874dfafd25p.png)  
  
**构建包**  
  
如果依赖包中存在二进制包需要进行编译，那么会在这一步进行。  
  
> 作者：酒窝yun过去了  
>   
> 链接：https://juejin.cn/post/7060844948316225572  
# 如何迁移仓库，同时保留原有的提交记录和分支？  
```  
git clone 仓库地址  
cd 项目  
git push --mirror 新的仓库地址  
```  
  
# 说说 git 发生冲突的场景？如何解决？  
  
 ![](https://static.vue-js.com/8aeccc40-fdb3-11eb-bc6f-3f06e1491664.png)  
  
## 一、是什么  
  
一般情况下，出现分支的场景有如下：  
  
- 多个分支代码合并到一个分支时  
- 多个分支向同一个远端分支推送  
  
具体情况就是，多个分支修改了同一个文件（任何地方）或者多个分支修改了同一个文件的名称  
  
如果两个分支中分别修改了不同文件中的部分，是不会产生冲突，直接合并即可  
  
应用在命令中，就是`push`、`pull`、`stash`、`rebase`等命令下都有可能产生冲突情况，从本质上来讲，都是`merge`和`patch`（应用补丁）时产生冲突  
  
  
  
## 二、分析  
  
在本地主分值`master`创建一个`a.txt`文件，文件起始位置写上`master commit`，如下：  
  
 ![](https://static.vue-js.com/959ade20-fdb3-11eb-991d-334fd31f0201.png)  
  
然后提交到仓库：  
  
- git add a.txt  
- git commit -m 'master first commit'  
  
创建一个新的分支`featurel1`分支，并进行切换，如下：  
  
```cmd  
git checkout -b featurel1  
```  
  
然后修改`a.txt`文件首行文字为 `featurel commit`，然后添加到暂存区，并开始进行提交到仓库：  
  
- git add a.txt  
- git commit -m 'featurel  first change'  
  
然后通过`git checkout master`切换到主分支，通过`git merge`进行合并，发现不会冲突  
  
此时`a.txt`文件的内容变成`featurel commit`，没有出现冲突情况，这是因为`git`在内部发生了快速合并  
  
> 如果当前分支的每一个提交(commit)都已经存在另一个分支里了，git 就会执行一个“快速向前”(fast forward)操作  
>  
> git 不创建任何新的提交(commit)，只是将当前分支指向合并进来的分支  
  
如果此时切换到`featurel`分支，将文件的内容修改成`featrue second commit`，然后提交到本地仓库  
  
然后切换到主分支，如果此时在`a.txt`文件再次修改，修改成`mastet second commit`，然后再次提交到本地仓库  
  
此时，`master`分支和`feature1`分支各自都分别有新的提交，变成了下图所示：  
  
 ![](https://static.vue-js.com/a05488c0-fdb3-11eb-991d-334fd31f0201.png)  
  
这种情况下，无法执行快速合并，只能试图把各自的修改合并起来，但这种合并就可能会有冲突  
  
现在通过`git merge featurel`进行分支合并，如下所示：  
  
 ![](https://static.vue-js.com/b0991d90-fdb3-11eb-bc6f-3f06e1491664.png)  
  
从冲突信息可以看到，`a.txt`发生冲突，必须手动解决冲突之后再提交  
  
而`git status`同样可以告知我们冲突的文件：  
  
 ![](https://static.vue-js.com/c5823430-fdb3-11eb-991d-334fd31f0201.png)  
  
打开`a.txt`文件，可以看到如下内容：  
  
 ![](https://static.vue-js.com/ce7a0a90-fdb3-11eb-bc6f-3f06e1491664.png)  
  
`git`用`<<<<<<<`，`=======`，`>>>>>>>`标记出不同分支的内容：  
  
- <<<<<<< 和 ======= 之间的区域就是当前更改的内容  
- ======= 和 >>>>>>> 之间的区域就是传入进来更改的内容  
  
现在要做的事情就是将冲突的内容进行更改，对每个文件使用 `git add` 命令来将其标记为冲突已解决。 一旦暂存这些原本有冲突的文件，`Git `就会将它们标记为冲突已解决然后再提交：  
  
- git add a.txt  
- git commit -m "conflict fixed"  
  
此时`master`分支和`feature1`分支变成了下图所示：  
  
 ![](https://static.vue-js.com/d7421e60-fdb3-11eb-bc6f-3f06e1491664.png)  
  
使用`git log`命令可以看到合并的信息：  
  
 ![](https://static.vue-js.com/e0dfd1b0-fdb3-11eb-991d-334fd31f0201.png)  
  
  
  
  
  
## 三、总结  
  
当`Git`无法自动合并分支时，就必须首先解决冲突，解决冲突后，再提交，合并完成  
  
解决冲突就是把`Git`合并失败的文件手动编辑为我们希望的内容，再提交  
  
# 说说你对git reset 和 git revert 的理解？区别？  
  
![](https://static.vue-js.com/046b4440-ff74-11eb-bc6f-3f06e1491664.png)  
  
  
## 一、是什么  
  
### git reset  
  
`reset`用于回退版本，可以遗弃不再使用的提交  
  
执行遗弃时，需要根据影响的范围而指定不同的参数，可以指定是否复原索引或工作树内容  
  
 ![](https://static.vue-js.com/ab4d0c00-ff72-11eb-bc6f-3f06e1491664.png)  
  
  
  
### git revert  
  
在当前提交后面，新增一次提交，抵消掉上一次提交导致的所有变化，不会改变过去的历史，主要是用于安全地取消过去发布的提交  
  
 ![](https://static.vue-js.com/bd12c290-ff72-11eb-991d-334fd31f0201.png)  
  
  
## 二、如何用  
  
### git reset  
  
当没有指定`ID`的时候，默认使用`HEAD`，如果指定`ID`，那么就是基于指向`ID`去变动暂存区或工作区的内容  
  
```cmd  
// 没有指定ID, 暂存区的内容会被当前ID版本号的内容覆盖，工作区不变  
git reset  
  
// 指定ID，暂存区的内容会被指定ID版本号的内容覆盖，工作区不变  
git reset <ID>   
```  
  
日志`ID`可以通过查询，可以`git log`进行查询，如下：  
  
```cmd  
commit a7700083ace1204ccdff9f71631fb34c9913f7c5 (HEAD -> master)  
Author: linguanghui <linguanghui@baidu.com>  
Date:   Tue Aug 17 22:34:40 2021 +0800  
  
    second commit  
  
commit e31118663ce66717edd8a179688a7f3dde5a9393  
Author: linguanghui <linguanghui@baidu.com>  
Date:   Tue Aug 17 22:20:01 2021 +0800  
  
    first commit  
```  
  
常见命令如下：  
  
- --mixed（默认）：默认的时候，只有暂存区变化  
  
- --hard参数：如果使用 --hard 参数，那么工作区也会变化  
  
- --soft：如果使用 --soft 参数，那么暂存区和工作区都不会变化  
  
 ![](https://static.vue-js.com/225b41e0-ff73-11eb-bc6f-3f06e1491664.png)  
  
  
  
### git revert  
  
跟`git reset`用法基本一致，`git revert` 撤销某次操作，此次操作之前和之后的 `commit`和`history`都会保留，并且把这次撤销，作为一次最新的提交，如下：  
  
```cmd  
git revert <commit_id>   
```  
  
如果撤销前一个版本，可以通过如下命令：  
  
```cmd  
git revert HEAD  
```  
  
撤销前前一次，如下：  
  
```cmd  
git revert HEAD^  
```  
  
## 三、区别  
  
撤销（revert）被设计为撤销公开的提交（比如已经push）的安全方式，`git reset`被设计为重设本地更改  
  
因为两个命令的目的不同，它们的实现也不一样：重设完全地移除了一堆更改，而撤销保留了原来的更改，用一个新的提交来实现撤销  
  
两者主要区别如下：  
  
- git revert是用一次新的commit来回滚之前的commit，git reset是直接删除指定的commit  
- git reset 是把HEAD向后移动了一下，而git revert是HEAD继续前进，只是新的commit的内容和要revert的内容正好相反，能够抵消要被revert的内容  
- 在回滚这一操作上看，效果差不多。但是在日后继续 merge 以前的老版本时有区别  
  
> git revert是用一次逆向的commit“中和”之前的提交，因此日后合并老的branch时，之前提交合并的代码仍然存在，导致不能够重新合并  
>  
> 但是git reset是之间把某些commit在某个branch上删除，因而和老的branch再次merge时，这些被回滚的commit应该还会被引入  
  
- 如果回退分支的代码以后还需要的情况则使用`git revert`， 如果分支是提错了没用的并且不想让别人发现这些错误代码，则使用`git reset`  
  
# 说说你对git rebase 和 git merge的理解？以及它们的区别？  
  
 ![](https://static.vue-js.com/77590970-fdd4-11eb-bc6f-3f06e1491664.png)  
  
## 一、是什么  
  
在使用 `git` 进行版本管理的项目中，当完成一个特性的开发并将其合并到 `master` 分支时，会有两种方式：  
  
- git merge  
- git rebase  
  
`git rebase` 与 `git merge`都有相同的作用，都是将一个分支的提交合并到另一分支上，但是在原理上却不相同  
  
  
  
用法上两者也十分的简单：  
  
### git merge  
  
将当前分支合并到指定分支，命令用法如下：  
  
```cmd  
git merge xxx  
```  
  
  
  
### git rebase  
  
将当前分支移植到指定分支或指定`commit`之上，用法如下：  
  
```cmd  
git rebase -i <commit>  
```  
  
常见的参数有`--continue`，用于解决冲突之后，继续执行`rebase`  
  
```cmd  
git rebase --continue  
```  
  
  
  
  
  
## 二、分析  
  
### git merge  
  
通过`git merge`将当前分支与`xxx`分支合并，产生的新的`commit`对象有两个父节点  
  
如果“指定分支”本身是当前分支的一个直接子节点，则会产生快照合并  
  
举个例子，`bugfix`分支是从`maste`r分支分叉出来的，如下所示：  
  
 ![](https://static.vue-js.com/88410a30-fdd4-11eb-991d-334fd31f0201.png)  
  
合并` bugfix`分支到`master`分支时，如果`master`分支的状态没有被更改过，即 `bugfix`分支的历史记录包含`master`分支所有的历史记录  
  
所以通过把`master`分支的位置移动到`bugfix`的最新分支上，就完成合并  
  
如果`master`分支的历史记录在创建`bugfix`分支后又有新的提交，如下情况：  
  
 ![](https://static.vue-js.com/929eb220-fdd4-11eb-991d-334fd31f0201.png)  
  
这时候使用`git merge`的时候，会生成一个新的提交，并且`master`分支的`HEAD`会移动到新的分支上，如下：  
  
 ![](https://static.vue-js.com/9fdfa3e0-fdd4-11eb-991d-334fd31f0201.png)  
  
  
  
从上面可以看到，会把两个分支的最新快照以及二者最近的共同祖先进行三方合并，合并的结果是生成一个新的快照  
  
  
  
### git rebase  
  
同样，`master`分支的历史记录在创建`bugfix`分支后又有新的提交，如下情况：  
  
 ![](https://static.vue-js.com/ab2d5120-fdd4-11eb-bc6f-3f06e1491664.png)  
  
通过`git rebase`，会变成如下情况：  
  
 ![](https://static.vue-js.com/b72aed70-fdd4-11eb-991d-334fd31f0201.png)  
  
在移交过程中，如果发生冲突，需要修改各自的冲突，如下：  
  
 ![](https://static.vue-js.com/c9ba0e80-fdd4-11eb-bc6f-3f06e1491664.png)  
  
`rebase`之后，`master`的`HEAD`位置不变。因此，要合并`master`分支和`bugfix`分支  
  
 ![](https://static.vue-js.com/dc660660-fdd4-11eb-991d-334fd31f0201.png)  
  
从上面可以看到，`rebase`会找到不同的分支的最近共同祖先，如上图的`B`  
  
然后对比当前分支相对于该祖先的历次提交，提取相应的修改并存为临时文件（老的提交`X`和`Y`也没有被销毁，只是简单地不能再被访问或者使用）  
  
然后将当前分支指向目标最新位置`D`, 然后将之前另存为临时文件的修改依序应用  
  
  
  
  
  
## 三、区别  
  
从上面可以看到，`merge`和`rebasea`都是合并历史记录，但是各自特性不同：  
  
### merge  
  
通过`merge`合并分支会新增一个`merge commit`，然后将两个分支的历史联系起来  
  
其实是一种非破坏性的操作，对现有分支不会以任何方式被更改，但是会导致历史记录相对复杂  
  
  
  
### rebase  
  
`rebase `会将整个分支移动到另一个分支上，有效地整合了所有分支上的提交  
  
主要的好处是历史记录更加清晰，是在原有提交的基础上将差异内容反映进去，消除了 ` git merge `所需的不必要的合并提交  
  
# 说说你对git stash 的理解？应用场景？  
  
 ![](https://static.vue-js.com/83ddf210-fd6f-11eb-bc6f-3f06e1491664.png)  
  
  
  
## 一、是什么  
  
stash，译为存放，在 git 中，可以理解为保存当前工作进度，会把暂存区和工作区的改动进行保存，这些修改会保存在一个栈上  
  
后续你可以在任何时候任何分支重新将某次的修改推出来，重新应用这些更改的代码  
  
默认情况下，`git stash`会缓存下列状态的文件：  
  
- 添加到暂存区的修改（staged changes）  
- Git跟踪的但并未添加到暂存区的修改（unstaged changes）  
  
但以下状态的文件不会缓存：  
  
- 在工作目录中新的文件（untracked files）  
- 被忽略的文件（ignored files）  
  
如果想要上述的文件都被缓存，可以使用`-u`或者`--include-untracked`可以工作目录新的文件，使用`-a`或者`--all`命令可以当前目录下的所有修改  
  
  
  
## 二、如何使用  
  
关于`git stash`常见的命令如下：  
  
- git stash  
- git stash save  
  
- git stash list  
- git stash pop  
- git stash apply  
- git stash show  
  
- git stash drop  
- git stash clear  
  
  
  
### git stash  
  
保存当前工作进度，会把暂存区和工作区的改动保存起来  
  
  
  
### git stash save  
  
`git stash save`可以用于存储修改.并且将`git`的工作状态切回到`HEAD`也就是上一次合法提交上  
  
如果给定具体的文件路径,`git stash`只会处理路径下的文件.其他的文件不会被存储，其存在一些参数：  
  
- --keep-index 或者 -k 只会存储为加入 git 管理的文件  
  
- --include-untracked 为追踪的文件也会被缓存,当前的工作空间会被恢复为完全清空的状态  
- -a 或者 --all 命令可以当前目录下的所有修改，包括被 git 忽略的文件  
  
  
  
### git stash list  
  
显示保存进度的列表。也就意味着，`git stash`命令可以多次执行，当多次使用`git stash`命令后，栈里会充满未提交的代码，如下：  
  
 ![](https://static.vue-js.com/50216dd0-fccf-11eb-bc6f-3f06e1491664.png)  
  
其中，`stash@{0}`、`stash@{1}`就是当前`stash`的名称  
  
  
  
### git stash pop  
  
`git stash pop` 从栈中读取最近一次保存的内容，也就是栈顶的`stash`会恢复到工作区  
  
也可以通过 `git stash pop` + `stash`名字执行恢复哪个`stash`恢复到当前目录  
  
如果从`stash`中恢复的内容和当前目录中的内容发生了冲突，则需要手动修复冲突或者创建新的分支来解决冲突  
  
  
  
  
  
### git stash apply  
  
将堆栈中的内容应用到当前目录，不同于`git stash pop`，该命令不会将内容从堆栈中删除  
  
也就说该命令能够将堆栈的内容多次应用到工作目录中，适应于多个分支的情况  
  
同样，可以通过`git stash apply` + `stash`名字执行恢复哪个`stash`恢复到当前目录  
  
  
  
  
  
  
  
### git stash show  
  
查看堆栈中最新保存的`stash`和当前目录的差异  
  
通过使用`git stash show -p`查看详细的不同  
  
通过使用`git stash show stash@{1}`查看指定的`stash`和当前目录差异  
  
 ![](https://static.vue-js.com/458620a0-fccf-11eb-bc6f-3f06e1491664.png)  
  
  
  
### git stash drop  
  
`git stash drop` + `stash`名称表示从堆栈中移除某个指定的stash  
  
  
  
### git stash clear  
  
删除所有存储的进度  
  
  
  
## 三、应用场景  
  
当你在项目的一部分上已经工作一段时间后，所有东西都进入了混乱的状态， 而这时你想要切换到另一个分支或者拉下远端的代码去做一点别的事情  
  
但是你创建一次未完成的代码的`commit`提交，这时候就可以使用`git stash`  
  
例如以下场景：  
  
当你的开发进行到一半,但是代码还不想进行提交 ,然后需要同步去关联远端代码时.如果你本地的代码和远端代码没有冲突时,可以直接通过`git pull`解决  
  
但是如果可能发生冲突怎么办.直接`git pull`会拒绝覆盖当前的修改，这时候就可以依次使用下述的命令：  
  
- git stash  
- git pull  
- git stash pop  
  
或者当你开发到一半，现在要修改别的分支问题的时候，你也可以使用`git stash`缓存当前区域的代码  
  
- git stash：保存开发到一半的代码  
- git commit -m '修改问题'  
- git stash pop：将代码追加到最新的提交之后  
# 说说对git pull 和 git fetch 的理解？有什么区别？  
  
  
 ![](https://static.vue-js.com/cc90c050-fac2-11eb-991d-334fd31f0201.png)  
  
  
  
## 一、是什么  
先回顾两个命令的定义  
- git fetch 命令用于从另一个存储库下载对象和引用  
- git pull 命令用于从另一个存储库或本地分支获取并集成(整合)  
  
再来看一次`git`的工作流程图，如下所示：  
  
 ![](https://static.vue-js.com/d523ba60-fac2-11eb-991d-334fd31f0201.png)  
  
可以看到，`git fetch`是将远程主机的最新内容拉到本地，用户在检查了以后决定是否合并到工作本机分支中  
  
而`git pull` 则是将远程主机的最新内容拉下来后直接合并，即：`git pull = git fetch + git merge`，这样可能会产生冲突，需要手动解决  
  
在我们本地的`git`文件中对应也存储了`git`本地仓库分支的`commit ID `和 跟踪的远程分支的`commit ID`，对应文件如下：  
  
-  .git/refs/head/[本地分支]  
-  .git/refs/remotes/[正在跟踪的分支]  
  
使用 `git fetch`更新代码，本地的库中`master`的`commitID`不变  
  
但是与`git`上面关联的那个`orign/master`的`commit ID`发生改变  
  
这时候我们本地相当于存储了两个代码的版本号，我们还要通过`merge`去合并这两个不同的代码版本  
  
 ![](https://static.vue-js.com/fd23ff70-fb12-11eb-bc6f-3f06e1491664.png)  
  
也就是`fetch`的时候本地的`master`没有变化，但是与远程仓关联的那个版本号被更新了，接下来就是在本地`merge`合并这两个版本号的代码  
  
相比之下，使用`git pull`就更加简单粗暴，会将本地的代码更新至远程仓库里面最新的代码版本，如下图：  
  
 ![](https://static.vue-js.com/091b8140-fb13-11eb-bc6f-3f06e1491664.png)  
  
  
  
  
  
## 二、用法  
  
一般远端仓库里有新的内容更新，当我们需要把新内容下载的时候，就使用到`git pull`或者`git fetch`命令  
  
### fetch  
  
用法如下：  
  
```cmd  
git fetch <远程主机名> <远程分支名>:<本地分支名>  
```  
  
例如从远程的`origin`仓库的`master`分支下载代码到本地并新建一个`temp`分支  
  
```cmd  
git fetch origin master:temp  
```  
  
如果上述没有冒号，则表示将远程`origin`仓库的`master`分支拉取下来到本地当前分支  
  
这里`git fetch`不会进行合并，执行后需要手动执行`git merge`合并，如下：  
  
```cmd  
git merge temp  
```  
  
  
  
### pull  
  
两者的用法十分相似，`pull`用法如下：  
  
```cmd  
git pull <远程主机名> <远程分支名>:<本地分支名>  
```  
  
例如将远程主机`origin`的`master`分支拉取过来，与本地的`branchtest`分支合并，命令如下：  
  
```cmd  
git pull origin master:branchtest  
```  
  
同样如果上述没有冒号，则表示将远程`origin`仓库的`master`分支拉取下来与本地当前分支合并  
  
  
  
## 三、区别  
  
相同点：  
  
- 在作用上他们的功能是大致相同的，都是起到了更新代码的作用  
  
不同点：  
  
- git pull是相当于从远程仓库获取最新版本，然后再与本地分支merge，即git pull = git fetch + git merge  
- 相比起来，git fetch 更安全也更符合实际要求，在 merge 前，我们可以查看更新情况，根据实际情况再决定是否合并  
  
# 说说Git 中 HEAD、工作树和索引之间的区别？  
 ![](https://static.vue-js.com/2de056a0-fa40-11eb-991d-334fd31f0201.png)  
  
## 一、HEAD  
  
在`git`中，可以存在很多分支，其本质上是一个指向`commit`对象的可变指针，而`Head`是一个特别的指针，是一个指向你正在工作中的本地分支的指针  
  
简单来讲，就是你现在在哪儿，HEAD 就指向哪儿  
  
例如当前我们处于`master`分支，所以`HEAD`这个指针指向了`master`分支指针  
  
 ![](https://static.vue-js.com/36cb0da0-fa40-11eb-991d-334fd31f0201.png)  
  
然后通过调用`git checkout test`切换到`test`分支，那么`HEAD`则指向`test`分支，如下图：  
  
 ![](https://static.vue-js.com/3e86ba80-fa40-11eb-991d-334fd31f0201.png)  
  
但我们在`test`分支再一次`commit`信息的时候，`HEAD`指针仍然指向了`test`分支指针，而`test`分支指针已经指向了最新创建的提交，如下图：  
  
 ![](https://static.vue-js.com/439839b0-fa66-11eb-991d-334fd31f0201.png)  
  
这个`HEAD`存储的位置就在`.git/HEAD`目录中，查看信息可以看到`HEAD`指向了另一个文件  
  
```cmd  
$ cat .git/HEAD  
ref: refs/heads/master  
  
$ cat .git/refs/heads/master  
7406a10efcc169bbab17827aeda189aa20376f7f  
```  
  
这个文件的内容是一串哈希码，而这个哈希码正是`master`分支上最新的提交所对应的哈希码  
  
所以，当我们切换分支的时候，`HEAD`指针通常指向我们所在的分支，当我们在某个分支上创建新的提交时，分支指针总是会指向当前分支的最新提交  
  
所以，HEAD指针 ——–> 分支指针 ——–> 最新提交  
  
  
  
## 二、工作树和索引  
  
在`Git`管理下，大家实际操作的目录被称为工作树，也就是工作区域  
  
在数据库和工作树之间有索引，索引是为了向数据库提交作准备的区域，也被称为暂存区域  
  
 ![](https://static.vue-js.com/46e5ac40-fa40-11eb-bc6f-3f06e1491664.png)  
  
`Git`在执行提交的时候，不是直接将工作树的状态保存到数据库，而是将设置在中间索引区域的状态保存到数据库  
  
因此，要提交文件，首先需要把文件加入到索引区域中。  
  
所以，凭借中间的索引，可以避免工作树中不必要的文件提交，还可以将文件修改内容的一部分加入索引区域并提交  
  
  
  
## 三、区别  
  
从所在的位置来看：  
  
- HEAD 指针通常指向我们所在的分支，当我们在某个分支上创建新的提交时，分支指针总是会指向当前分支的最新提交  
  
- 工作树是查看和编辑的（源）文件的实际内容  
  
- 索引是放置你想要提交给 git仓库文件的地方，如工作树的代码通过 git add 则添加到 git 索引中，通过git commit 则将索引区域的文件提交到 git 仓库中  
  
# 说说Git常用的命令有哪些？  
 ![](https://static.vue-js.com/f66b3290-f7af-11eb-bc6f-3f06e1491664.png)  
  
  
## 一、前言  
  
`git `的操作可以通过命令的形式如执行，日常使用就如下图6个命令即可  
  
 ![](https://static.vue-js.com/fe150520-f7af-11eb-991d-334fd31f0201.png)  
  
实际上，如果想要熟练使用，超过60多个命令需要了解，下面则介绍下常见的的`git `命令  
  
  
  
## 二、有哪些  
  
  
  
  
  
## 配置  
  
`Git `自带一个 `git config` 的工具来帮助设置控制 `Git `外观和行为的配置变量，在我们安装完`git`之后，第一件事就是设置你的用户名和邮件地址  
  
后续每一个提交都会使用这些信息，它们会写入到你的每一次提交中，不可更改  
  
设置提交代码时的用户信息命令如下：  
  
- git config [--global] user.name "[name]"   
- git config [--global] user.email "[email address]"  
  
  
  
  
  
### 启动  
  
一个`git`项目的初始有两个途径，分别是：  
  
- git init [project-name]：创建或在当前目录初始化一个git代码库  
- git clone url：下载一个项目和它的整个代码历史  
  
  
  
### 日常基本操作  
  
在日常工作中，代码常用的基本操作如下：  
  
- git init 初始化仓库，默认为 master 分支  
- git add . 提交全部文件修改到缓存区  
- git add <具体某个文件路径+全名> 提交某些文件到缓存区  
- git diff  查看当前代码 add后，会 add 哪些内容  
- git diff --staged查看现在 commit 提交后，会提交哪些内容  
- git status 查看当前分支状态  
- git pull <远程仓库名> <远程分支名> 拉取远程仓库的分支与本地当前分支合并  
- git pull <远程仓库名> <远程分支名>:<本地分支名> 拉取远程仓库的分支与本地某个分支合并  
- git commit -m "<注释>" 提交代码到本地仓库，并写提交注释  
- git commit -v 提交时显示所有diff信息  
- git commit --amend [file1] [file2] 重做上一次commit，并包括指定文件的新变化  
  
关于提交信息的格式，可以遵循以下的规则：  
  
- feat: 新特性，添加功能  
- fix: 修改 bug  
- refactor: 代码重构  
- docs: 文档修改  
- style: 代码格式修改, 注意不是 css 修改  
- test: 测试用例修改  
- chore: 其他修改, 比如构建流程, 依赖管理  
  
  
  
### 分支操作  
  
- git branch 查看本地所有分支  
- git branch -r 查看远程所有分支  
- git branch -a 查看本地和远程所有分支  
- git merge <分支名> 合并分支  
- git merge --abort 合并分支出现冲突时，取消合并，一切回到合并前的状态  
- git branch <新分支名> 基于当前分支，新建一个分支  
- git checkout --orphan <新分支名> 新建一个空分支（会保留之前分支的所有文件）  
- git branch -D <分支名> 删除本地某个分支  
- git push <远程库名> :<分支名> 删除远程某个分支  
- git branch <新分支名称> <提交ID> 从提交历史恢复某个删掉的某个分支  
- git branch -m <原分支名> <新分支名> 分支更名  
- git checkout <分支名> 切换到本地某个分支  
- git checkout <远程库名>/<分支名> 切换到线上某个分支  
- git checkout -b <新分支名> 把基于当前分支新建分支，并切换为这个分支  
  
  
  
  
  
### 远程同步  
  
远程操作常见的命令：  
  
- git fetch [remote] 下载远程仓库的所有变动  
- git remote -v 显示所有远程仓库  
- git pull [remote] [branch] 拉取远程仓库的分支与本地当前分支合并  
- git fetch 获取线上最新版信息记录，不合并  
- git push [remote] [branch] 上传本地指定分支到远程仓库  
- git push [remote] --force 强行推送当前分支到远程仓库，即使有冲突  
- git push [remote] --all 推送所有分支到远程仓库  
  
  
  
### 撤销  
  
- git checkout [file] 恢复暂存区的指定文件到工作区  
- git checkout [commit] [file]  恢复某个commit的指定文件到暂存区和工作区  
- git checkout . 恢复暂存区的所有文件到工作区  
- git reset [commit] 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变  
- git reset --hard 重置暂存区与工作区，与上一次commit保持一致  
- git reset [file] 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变  
  
- git revert [commit]  后者的所有变化都将被前者抵消，并且应用到当前分支  
  
> `reset`：真实硬性回滚，目标版本后面的提交记录全部丢失了  
>  
> `revert`：同样回滚，这个回滚操作相当于一个提价，目标版本后面的提交记录也全部都有  
  
  
  
### 存储操作  
  
你正在进行项目中某一部分的工作，里面的东西处于一个比较杂乱的状态，而你想转到其他分支上进行一些工作，但又不想提交这些杂乱的代码，这时候可以将代码进行存储  
  
- git stash 暂时将未提交的变化移除  
- git stash pop 取出储藏中最后存入的工作状态进行恢复，会删除储藏  
  
- git stash list 查看所有储藏中的工作  
- git stash apply <储藏的名称>  取出储藏中对应的工作状态进行恢复，不会删除储藏  
- git stash clear 清空所有储藏中的工作  
- git stash drop <储藏的名称>  删除对应的某个储藏  
  
  
  
## 三、总结  
  
`git`常用命令速查表如下所示：  
  
 ![](https://static.vue-js.com/0a10f3c0-f7b0-11eb-991d-334fd31f0201.png)  
  
# 说说Git中 fork, clone,branch这三个概念，有什么区别?  
 ![](https://static.vue-js.com/9c4eb9a0-f7ad-11eb-bc6f-3f06e1491664.png)  
  
  
  
## 一、是什么  
  
### fork  
  
`fork`，英语翻译过来就是叉子，动词形式则是分叉，如下图，从左到右，一条直线变成多条直线  
  
 ![](https://static.vue-js.com/ad04ade0-f7ad-11eb-991d-334fd31f0201.png)  
  
转到`git`仓库中，`fork`则可以代表分叉、克隆 出一个（仓库的）新拷贝  
  
 ![](https://static.vue-js.com/b4b31450-f7ad-11eb-991d-334fd31f0201.png)  
  
包含了原来的仓库（即upstream repository，上游仓库）所有内容，如分支、Tag、提交  
  
如果想将你的修改合并到原项目中时，可以通过的 Pull Request 把你的提交贡献回 原仓库  
  
### clone  
  
`clone`，译为克隆，它的作用是将文件从远程代码仓下载到本地，从而形成一个本地代码仓  
  
执行`clone`命令后，会在当前目录下创建一个名为`xxx`的目录，并在这个目录下初始化一个 `.git` 文件夹，然后从中读取最新版本的文件的拷贝  
  
默认配置下远程 `Git` 仓库中的每一个文件的每一个版本都将被拉取下来  
  
### branch  
  
`branch`，译为分支，其作用简单而言就是开启另一个分支， 使用分支意味着你可以把你的工作从开发主线上分离开来，以免影响开发主线  
  
` Git` 处理分支的方式十分轻量，创建新分支这一操作几乎能在瞬间完成，并且在不同分支之间的切换操作也是一样便捷  
  
在我们开发中，默认只有一条`master`分支，如下图所示：  
  
 ![](https://static.vue-js.com/7fa8e9c0-f923-11eb-991d-334fd31f0201.png)  
  
通过`git branch `可以创建一个分支，但并不会自动切换到新分支中去  
  
 ![](https://static.vue-js.com/89efd560-f923-11eb-bc6f-3f06e1491664.png)  
  
通过`git checkout`可以切换到另一个`testing`分支  
  
 ![](https://static.vue-js.com/91d1cef0-f923-11eb-bc6f-3f06e1491664.png)  
  
  
## 二、如何使用  
  
### fork  
  
当你在`github`发现感兴趣开源项目的时候，可以通过点击`github`仓库中右上角`fork`标识的按钮，如下图：  
  
 ![](https://static.vue-js.com/bc4c4510-f7ad-11eb-991d-334fd31f0201.png)  
  
点击这个操作后会将这个仓库的文件、提交历史、issues和其余东西的仓库复制到自己的`github`仓库中，而你本地仓库是不会存在任何更改  
  
然后你就可以通过`git clone`对你这个复制的远程仓库进行克隆  
  
后续更改任何东西都可以在本地完成，如`git add`、`git commit`一系列的操作，然后通过`push`命令推到自己的远程仓库  
  
如果希望对方接受你的修改，可以通过发送`pull requests`给对方，如果对方接受。则会将你的修改内容更新到仓库中  
  
 ![](https://static.vue-js.com/c5265a40-f7ad-11eb-991d-334fd31f0201.png)  
  
整体流程如下图：  
  
 ![](https://static.vue-js.com/ced8ce10-f7ad-11eb-bc6f-3f06e1491664.png)  
  
  
### clone  
  
在`github`中，开源项目右侧存在`code`按钮，点击后则会显示开源项目`url`信息，如下图所示：  
  
 ![](https://static.vue-js.com/d8685090-f7ad-11eb-bc6f-3f06e1491664.png)  
  
通过`git clone xxx`则能完成远程项目的下载  
  
  
### branch  
  
可通过`git branch`进行查看当前的分支状态，  
  
如果给了`--list`，或者没有非选项参数，现有的分支将被列出；当前的分支将以绿色突出显示，并标有星号  
  
以及通过`git branch`创建一个新的分支出来  
  
  
## 三、区别  
  
其三者区别如下：  
  
- fork 只能对代码仓进行操作，且 fork 不属于 git 的命令，通常用于代码仓托管平台的一种“操作”  
- clone 是 git 的一种命令，它的作用是将文件从远程代码仓下载到本地，从而形成一个本地代码仓  
- branch 特征与 fork 很类似，fork 得到的是一个新的、自己的代码仓，而 branch 得到的是一个代码仓的一个新分支  
  
# 说说你对Git的理解？  
 ![](https://static.vue-js.com/213eba50-f79c-11eb-bc6f-3f06e1491664.png)  
  
## 一、是什么  
  
git，是一个分布式版本控制软件，最初目的是为更好地管理`Linux`内核开发而设计  
  
分布式版本控制系统的客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来。这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复  
  
 ![](https://static.vue-js.com/29240f40-f79c-11eb-991d-334fd31f0201.png)  
  
项目开始，只有一个原始版仓库，别的机器可以`clone`这个原始版本库，那么所有`clone`的机器，它们的版本库其实都是一样的，并没有主次之分  
  
所以在实现团队协作的时候，只要有一台电脑充当服务器的角色，其他每个人都从这个“服务器”仓库`clone`一份到自己的电脑上，并且各自把各自的提交推送到服务器仓库里，也从服务器仓库中拉取别人的提交  
  
`github`实际就可以充当这个服务器角色，其是一个开源协作社区，提供`Git`仓库托管服务，既可以让别人参与你的开源项目，也可以参与别人的开源项目  
  
  
  
## 二、工作原理  
  
当我们通过`git init`创建或者`git clone`一个项目的时候，项目目录会隐藏一个`.git`子目录，其作用是用来跟踪管理版本库的  
  
`Git` 中所有数据在存储前都计算校验和，然后以校验和来引用，所以在我们修改或者删除文件的时候，`git`能够知道  
  
`Git `用以计算校验和的机制叫做 SHA-1 散列（hash，哈希）， 这是一个由 40 个十六进制字符（0-9 和 a-f）组成字符串，基于 Git 中文件的内容或目录结构计算出来，如下：  
  
```text  
24b9da6552252987aa493b52f8696cd6d3b00373  
```  
  
当我们修改文件的时候，`git`就会修改文件的状态，可以通过`git status`进行查询，状态情况如下：  
  
- 已修改（modified）：表示修改了文件，但还没保存到数据库中。  
- 已暂存（staged）：表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。  
- 已提交（committed）：表示数据已经安全的保存在本地数据库中。  
  
文件状态对应的，不同状态的文件在` Git `中处于不同的工作区域，主要分成了四部分：  
  
- 工作区：相当于本地写代码的区域，如 git clone 一个项目到本地，相当于本地克隆了远程仓库项目的一个副本  
- 暂存区：暂存区是一个文件，保存了下次将提交的文件列表信息，一般在 Git 仓库目录中  
- 本地仓库：提交更新，找到暂存区域的文件，将快照永久性存储到 Git 本地仓库  
- 远程仓库：远程的仓库，如 github  
  
 ![](https://static.vue-js.com/3273c9a0-f79c-11eb-bc6f-3f06e1491664.png)  
  
  
  
## 三、命令  
  
从上图可以看到，`git`日常简单的使用就只有上图6个命令：  
  
- add  
- commit   
- push  
- pull  
- clone  
- checkout  
  
但实际上还有很多命令，如果想要熟练使用，还有60个多命令，通过这些命令的配合使用，能够提高个人工作效率和团队协助能力  
# 说说你对版本管理的理解？  
版本控制（Version control），是维护工程蓝图的标准作法，能追踪工程蓝图从诞生一直到定案的过程。此外，版本控制也是一种软件工程技巧，借此能在软件开发的过程中，确保由不同人所编辑的同一程序文件都得到同步  
  
透过文档控制，能记录任何工程项目内各个模块的改动历程，并为每次改动编上序号  
  
一种简单的版本控制形式如下：赋给图的初版一个版本等级“A”。当做了第一次改变后，版本等级改为“B”，以此类推  
  
版本控制能提供项目的设计者，将设计恢复到之前任一状态的选择权  
  
简言之，你的修改只要提到到版本控制系统，基本都可以找回，版本控制系统就像一台时光机器，可以让你回到任何一个时间点  
# 如何检查Javascript中的内存泄漏？  
## 浏览器  
  
Chrome 浏览器查看内存占用，按照以下步骤操作。  
  
![image.png](https://i.loli.net/2021/09/25/luOGHT7a2EqMSf1.png)  
  
```  
1、打开开发者工具，选择 Timeline 面板  
2、在顶部的Capture字段里面勾选 Memory  
3、点击左上角的录制按钮。  
4、在页面上进行各种操作，模拟用户的使用情况。  
5、一段时间后，点击对话框的 stop 按钮，面板上就会显示这段时间的内存占用情况。  
```  
  
如果内存占用基本平稳，接近水平，就说明不存在内存泄漏。  
  
![image.png](https://i.loli.net/2021/09/25/1jnvlaB8CY7Rqup.png)  
  
反之，就是内存泄漏了。  
  
![image.png](https://i.loli.net/2021/09/25/wUHKg48oArEZMt1.png)  
  
## 命令行  
  
命令行可以使用 Node 提供的process.memoryUsage方法。  
  
```js  
console.log(process.memoryUsage());  
// { rss: 27709440,  
//  heapTotal: 5685248,  
//  heapUsed: 3449392,  
//  external: 8772 }  
```  
  
process.memoryUsage返回一个对象，包含了 Node 进程的内存占用信息。该对象包含四个字段，单位是字节，含义如下。  
  
![image.png](https://i.loli.net/2021/09/25/Hncwkesmfd5iuG8.png)  
  
```  
rss（resident set size）：所有内存占用，包括指令区和堆栈。  
heapTotal："堆"占用的内存，包括用到的和没用到的。  
heapUsed：用到的堆的部分。  
external： V8 引擎内部的 C++ 对象占用的内存。  
```  
  
判断内存泄漏，以 `heapUsed` 字段为准。  
  
  
  
  
# 谈谈对 babel-polyfill 的了解  
babel polyfill 有三种：  
  
* babel-polyfill  
* babel-runtime  
* babel-plugin-transform-runtime  
  
## babel-polyfill  
  
babel-polyfill通过向全局对象和内置对象的prototype上添加方法来实现的。所以这会造成全局空间污染。  
  
babel-polyfill使用的两种方式：  
  
* webpack.config.js 中：  
  
配置webpack.config.js里的entry设置为entry: ['babel-polyfill',path.join(__dirname, 'index.js')]  
  
* 业务 js 中：  
  
在webpack.config.js配置的主入口index.js文件的最顶层键入  
  
```js  
import 'babel-polyfill'  
```  
  
两者打印出来的大小都是一样的，打包后大小是280KB，如果没有使用babel-polyfill，大小是3.43kb。  
  
两则相差大概81.6倍。原因是webpack把babel-polyfill整体全部都打包进去了。而babel-polyfill肯定也实现了所有ES6新API的垫片,文件一定不会小。  
  
那么有没有一种办法,根据实际代码中用到的ES6新增API ,来使用对应的垫片,而不是全部加载进去呢?  
  
是的，有的。那就是 `babel-runtime & babel-plugin-transform-runtime`，他们可以实现按需加载。  
  
## babel-runtime  
  
简单说 babel-runtime 更像是一种按需加载的实现，比如你哪里需要使用 Promise，只要在这个文件头部  
  
```js  
import Promise from 'babel-runtime/core-js/promise'  
```  
  
就行了。  
  
不过如果你许多文件都要使用 Promise，难道每个文件都要 import 一下吗？当然不是，Babel 官方已考虑这种情况，只需要使用 babel-plugin-transform-runtime 就可以解决手动 import 的苦恼了。  
  
## babel-plugin-transform-runtime  
  
babel-plugin-transform-runtime 装了就不需要装 babel-runtime了，因为前者依赖后者。  
总的来说，babel-plugin-transform-runtime 就是可以在我们使用新 API 时 自动 import babel-runtime 里面的 polyfill，具体插件做了以下三件事情：  
  
* 当我们使用 async/await 时，自动引入 babel-runtime/regenerator  
* 当我们使用 ES6 的静态事件或内置对象时，自动引入 babel-runtime/core-js  
* 移除内联 babel helpers 并替换使用 babel-runtime/helpers  来替换  
  
babel-plugin-transform-runtime 优点：  
  
* 不会污染全局变量  
* 多次使用只会打包一次  
* 依赖统一按需引入,无重复引入,无多余引入  
* 避免 babel 编译的工具函数在每个模块里重复出现，减小库和工具包的体积  
  
使用方式：  
  
在 .babelrc 中配置：  
  
```  
plugins: ["tranform-runtime"]  
```  
  
打包后大小为 17.4kb，比之前的280kb要小很多。  
  
  
  
# babel 和 babel ployfill 有什么关系？  
* 先来理解下 babel 到底是做什么的？  
  
简单来讲，babel解决语法层面的问题。用于将ES6+的高级语法转为ES5。  
  
* babel polyfill 又是做什么的？  
  
如果要解决API层面的问题，需要使用垫片。比如常见的有babel-polyfill、babel-runtime 和 babel-plugin-transform-runtime。  
  
# ESLint 是什么？  
ESLint是一个用来识别 ECMAScript 并且按照规则给出报告的代码检测工具，使用它可以避免低级错误和统一代码的风格。如果每次在代码提交之前都进行一次eslint代码检查，就不会因为某个字段未定义为undefined或null这样的错误而导致服务崩溃，可以有效的控制项目代码的质量。  
  
在许多方面，它和 JSLint、JSHint 相似，除了少数的例外：  
  
* ESLint 使用 Espree 解析 JavaScript。  
* ESLint 使用 AST 去分析代码中的模式。  
* ESLint 是完全插件化的。每一个规则都是一个插件并且你可以在运行时添加更多的规则。  
  
# babel-polyfill 有什么用？  
Babel默认只转换新的JavaScript句法（syntax），而不转换新的API，比如Iterator、Generator、Set、Maps、Proxy、Reflect、Symbol、Promise等全局对象，以及一些定义在全局对象上的方法（比如Object.assign）都不会转码。  
  
举例来说，ES6在Array对象上新增了Array.from方法。Babel就不会转码这个方法。如果想让这个方法运行，必须使用babel-polyfill，为当前环境提供一个垫片。  
  
  
# 数据Mock是什么？  
Mock 数据是前端开发过程中必不可少的一环，是分离前后端开发的关键链路。   
  
通过预先跟服务器端约定好的接口，模拟请求数据甚至逻辑，能够让前端开发独立自主，不会被服务端的开发所阻塞。  
  
前后端同时开发的时候，后端接口数据没有出来，前端可以mock假数据，模拟开发。  
  
Mock.js 是常用的辅助生成模拟数据的三方库，借助他可以提升我们的 mock 数据能力。  
  
  
# 怎么进行移动端的调试？  
* vConsole：Web 调试面板  
  
vConsole 会在你网页中加一个悬浮的小按钮，可以点击它来打开关闭调试面板，并查看 DOM、Console、Network和 本地存储 等信息。基本可以满足普通前端开发的需求。使用方法也很简单，通过npm安装或者直接在需要的页面引入 js文件 ，然后 new VConsole() 就可以了。  
  
*  Charles  
  
Charles 是一款强大的抓包工具，可以截取包括 https 在内的各种网络请求并方便的查看具体信息。有 Mac、Windows 和 Linux多版本，通过配置 WIFI 代理，也可以拦截手机发出的请求。毕竟前端相当一部分报错是网络错误或数据不符合预期导致的（甩锅后端😄）。所以通过拦截 http 请求,查看具体的请求信息和数据，能获取很多有用的信息，可以在一定程度上帮助 debug。  
  
* Chrome浏览器 + Android  
  
使用Chrome中的 Inspect，直接在PC端调试android机器中的webview的页面。  
  
* Mac + IOS + Safari  
  
方法基本同上  
  
# 怎么使用 git 将多次提交压缩成一次提交？  
在使用 Git 作为版本控制的时候，我们可能会由于各种各样的原因提交了许多临时的 commit，而这些 commit 拼接起来才是完整的任务。那么我们为了避免太多的 commit 而造成版本控制的混乱，通常我们推荐将这些 commit 合并成一个。  
  
* 查看提交历史，git log  
  
首先你要知道自己想合并的是哪几个提交，可以使用git log命令来查看提交历史，假如最近4条历史如下：  
  
```  
commit 3ca6ec340edc66df13423f36f52919dfa3......  
  
commit 1b4056686d1b494a5c86757f9eaed844......  
  
commit 53f244ac8730d33b353bee3b24210b07......  
  
commit 3a4226b4a0b6fa68783b07f1cee7b688.......  
```  
  
历史记录是按照时间排序的，时间近的排在前面。  
  
* git rebase  
  
想要合并1-3条，有两个方法：  
  
1.从HEAD版本开始往过去数3个版本  
```  
git rebase -i HEAD~3  
```  
  
2.指名要合并的版本之前的版本号  
```  
git rebase -i 3a4226b  
```  
请注意3a4226b这个版本是不参与合并的，可以把它当做一个坐标  
  
* 选取要合并的提交  
  
1.执行了rebase命令之后，会弹出一个窗口，头几行如下：  
```  
pick 3ca6ec3   '注释**********'  
  
pick 1b40566   '注释*********'  
  
pick 53f244a   '注释**********'  
```  
  
2.将pick改为squash或者s,之后保存并关闭文本编辑窗口即可。改完之后文本内容如下：  
  
```  
pick 3ca6ec3   '注释**********'  
  
s 1b40566   '注释*********'  
  
s 53f244a   '注释**********'  
```  
  
3.然后保存退出，Git会压缩提交历史，如果有冲突，需要修改，修改的时候要注意，保留最新的历史，不然我们的修改就丢弃了。修改以后要记得敲下面的命令：  
```  
git add .    
  
git rebase --continue    
```  
  
如果你想放弃这次压缩的话，执行以下命令：  
  
```  
git rebase --abort    
```  
  
4.如果没有冲突，或者冲突已经解决，则会出现如下的编辑窗口：  
```  
# This is a combination of 4 commits.    
#The first commit’s message is:    
注释......  
# The 2nd commit’s message is:    
注释......  
# The 3rd commit’s message is:    
注释......  
# Please enter the commit message for your changes. Lines starting # with ‘#’ will be ignored, and an empty message aborts the commit.  
```  
  
5.输入wq保存并推出, 再次输入git log查看 commit 历史信息，你会发现这两个 commit 已经合并了。  
# 什么是 git stash？  
通常情况下，当你一直在处理项目的某一部分时，如果你想要在某个时候切换分支去处理其他事情，事情会处于混乱的状态。问题是，你不想把完成了一半的工作的提交，以便你以后就可以回到当前的工作。解决这个问题的答案是 git stash。  
  
再解释什么是git stash。  
  
stash 会将你的工作目录，即修改后的跟踪文件和暂存的更改保存在一堆未完成的更改中，你可以随时重新应用这些更改。  
  
  
# git pull 和 git fetch 有什么区别？  
git pull 命令从中央存储库中提取特定分支的新更改或提交，并更新本地存储库中的目标分支。  
  
git fetch 也用于相同的目的，但它的工作方式略有不同。当你执行 git fetch 时，它会从所需的分支中提取所有新提交，并将其存储在本地存储库中的新分支中。如果要在目标分支中反映这些更改，必须在 git fetch 之后执行git merge。只有在对目标分支和获取的分支进行合并后才会更新目标分支。为了方便起见，请记住以下等式：  
  
>git pull = git fetch + git merge  
# Git，GitHub与GitLab分别是什么？有什么区别？  
  
* Git是一款免费、开源的分布式版本控制系统  
* GitHub是一个面向开源及私有软件项目的托管平台，因为只支持git作为唯一的版本库格式进行托管，故名GitHub。  
* GitLab 是一个用于仓库管理系统的开源项目，使用Git作为代码管理工具，并在此基础上搭建起来的web服务。安装方法是参考GitLab在GitHub上的Wiki页面。  
  
## Git，GitHub与GitLab的区别  
  
* Git是一种版本控制系统，是一种工具，用于代码的存储和版本控制。  
* GitHub是一个基于Git实现的在线代码仓库，是目前全球最大的代码托管平台，可以帮助程序员之间互相交流和学习。  
* GitLab是一个基于Git实现的在线代码仓库软件，你可以用GitLab自己搭建一个类似于GitHub一样的仓库，但是GitLab有完善的管理界面和权限控制，一般用于在企业、学校等内部网络搭建Git私服。  
* GitHub和GiLlab两个都是基于Web的Git远程仓库，它们都提供了分享开源项目的平台，为开发团队提供了存储、分享、发布和合作开发项目的中心化云存储的场所。从代码的私有性上来看，GitLab 是一个更好的选择。但是对于开源项目而言，GitHub 依然是代码托管的首选。  
  
  
  
